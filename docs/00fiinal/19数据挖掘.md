# 一、数据挖掘
## 1.什么是数据挖掘


### 1.1.数据挖掘发展
#### （1）起源
世纪之交，人类面临着新的问题：不缺数据缺知识。随着数据库技术的成熟和数据应用的普及，人类积累的数据量正以指数速度发展。这些庞大的数据库及其中的海量数据是极其丰富的信息源，但是仅仅依靠传统的数据检索机制和统计分析方法已经远远不能满足需要了。因此，从数据库中发现知识极其核心技术，数据挖掘应用而生。
- 发现知识：知识发现是识别出存在于数据库中有效的、新颖的、具有潜在价值的模式的过程。
- 数据挖掘：数据挖掘则是指从数据库的大量数据中揭示出隐含的、先前未知的并有潜在价值的信息的过程。
- 知识发现和数据挖掘不同：这两个术语的内涵大致相同，严格区分的话，知识发现是从数据库中发现知识的全部过程；数据挖掘则是此全部过程的一个特定的关键步骤，这种定义把数据挖掘的对象定义为数据库。

决策支持系统：
- 传统的决策支持系统中，知识库中的知识和规则是由专家建立的
- 对于大量数据数据，即使是管理这些数据的专家也是没有能力发现的，这些信息对于决策可能是至关重要的，这类问题就可以用数据挖掘来对付。

#### （2）数据挖掘定义
数据挖掘广义的说法是，数据挖掘意味着在一些事实或观察数据的集合中寻找模式的决策支持过程。实际上，数据挖掘的对象不仅是数据库，也可以是文件系统，或其他任何组织在一起的数据集合。数据挖掘的最新对象是数据仓库。

#### （3）数据挖掘的目的

>挖掘知识 -> 决策

数据挖掘的任务是从大量数据中发现知识，数据挖掘是知识发现的核心技术。数据挖掘发现的知识可以直接提供给决策者，用于辅助决策过程；或者提供给领域专家，修正专家已有的知识体系；也可以作为新的知识转存到应用系统的知识存储机构中，比如专家系统规则库。

#### （4）数据挖掘的过程
图：数据挖掘过程图<br>
![数据挖掘过程图](img/数据挖掘过程图.jpeg)

通过数据挖掘过程图可知，知识发现有以下四个主要的阶段：采集选择、数据预处理、数据挖掘、解释评价。
- 采集选择<br>
采集选择的目的是辨别出需要分析的数据集合，缩小处理范围。
- 数据预处理<br>
数据预处理包括数据集成、数据清理、数据变换、数据简化。
- 数据挖掘<br>
现决定是发现型还是验证型的数据数据，然后选择合适的工具，进行发现知识的操作及验证发现的知识。
- 解释评价<br>
这一步骤不仅是把结果表达出来（例如采用信息可视化方法），还要对信息进行过滤处理，如果不能令决策者满意，需要重复以上数据挖掘的过程。

#### （5）数据挖掘解决的问题


### 1.2.数据挖掘&机器学习&数据分析
#### （1）数据挖掘与机器学习比较
数据挖掘与机器学习都是从数据中提取知识，区别在于，<u>机器学习主要针对「特定模式」的数据进行学习；数据挖掘则是从实际的海量数据源中抽取知识，如数据仓库。</u>

### 1.3.数据挖掘方法
数据挖掘的研究融合了多个不同学科领域的技术成果，其方法由人工智能、机器学习的方法发展而来，形成了以下几种数据挖掘的方法。

通常情况下，我们把数据挖掘方法分为两大方面：一是数理统计领域中的统计类型，二是人工智能领域中的机器学习型。
- 统计型：概率分析、相关性、聚类分析和判别式等常用技术
- 机器学习型：通过训练和学习大量的样品集获得需要的模式或参数。

#### （1）统计分析方法（数理统计分析）
- 统计分析方法是利用「统计学原理」对数据库中的数据进行分析，从而找出他们之间的关系和规律的方法。统计分析一直是分析「空间数据」的常用方法，侧重空间物体和现象的非空间特性分析。
- 数理统计分析建立在传统的数理统计基础上。在数据库字段项之间存在两种关系：函数关系和相关关系。函数关系是能用函数公式表示的确定性关系；相关关系是不能用函数公式表示，但仍是相关确定性关系。对他们的分析可采用统计学方法，即利用统计学原理对数据库中的信息进行分析。
- 统计分析方法较多，如描述统计，概率论、回归分析、多元分析等，统计分析方法是利用统计学、概率论的原理进行分析统计，从而找出相应规律的方法。

统计分析方法包括：
- 线性分析
- 非线性分析
- 相关分析
- 回归分析
>回归分析是通过使用变量之间相互依存的定量关系来分析和预测的统计分析方法。
- 差异分析
- 判别分析
- bayes网络
- 常用统计
- 多元回归分析
- 最小二乘回归方法
- 描述统计
- 时间序列分析
>时间序列分析是按照对象的规律或趋势建立时间序列模型，利用时间序列模型进行分析的方法。
- 多元分析
>多元分析主要对主成分、因子、判别、聚类即典型相关等进行分析的方法，通常用于对多维随机变量进行分析。

###### 统计分析方法的缺点：
统计分析方法的缺点是难以处理字符型数据，需要具有领域知识和统计知识，一般由具有统计经验的领域专家来完成。

#### （2）决策树
#### （3）人工神经网络

## （一）数据挖掘介绍
## （二）认识数据
数据挖掘的第一步就是认识数据，了解数据。
### 1.数据类型
- 用来描述数据对象的属性可以具有不同的类型，定量或者定性的。
- 数据的类型决定我们应使用何种工具和技术来分析数据。

#### （1）数据集
>数据集可以看做数据对象的集合。
- 通常，数据集是一个文件，其中对象是文件的记录（或行），而每个字段（或列）对应于一个属性。
- 基于记录的数据集在关系数据库系统中是最常见的。

##### 数据集特性
- 维度：数据集的维度是数据集中对象具有的属性数目。低维数据与中、高维数据有质的区别。分析高维数据往往陷入维度灾难。数据预处理有时减少维度或称为维规约就是为了避免陷入维度灾难。
- 稀疏性：有些数据集，如具有非对称特征的数据集，一个对象的大部分属性上的值都为0，在许多情况下，非零项还不到1%。稀疏性有时是一个优点，可节省计算时间和存储空间。有些数据挖掘算法仅适合处理稀疏数据。
- 分辨率：

##### 数据集类型
我们分析三种数据集类型：记录数据、基于图形的数据、有序数据。
- 记录数据：
- 基于图形的数据：
- 有序数据：对于某些数据类型，属性具有涉及时间或空间序的联系。
    - 时序数据：时序数据也称时间数据，每个记录包含一个与之相关联的时间。时间序列数据是一种特殊的时序数据，其中每个记录都是一个时间序列，即一段时间以来的测量序列。例如：金融数据集可能包含各种股票每日价格的事件序列对象。
    - 序列数据：序列数据是一个数据集合，它是各个实体的序列，如词或字母的序列。除没有时间戳之外，它与时序数据非常相似，只是有序序列考虑项的位置。空间数据除了其他类型的属性之外，还具有空间属性，如位置或区域。

#### （2）数据对象
> 数据对象有时也叫作记录、点、向量、模式、事件、案例、样本、观测或实体。数据对象用一组刻画对象基本特性的属性描述。

#### （3）属性
>属性有时也叫作变量、特性、字段、特征或维。属性是对象的性质或特性，它因对象而异，或随时间而变化。
- 例如：眼球颜色因人而异，物体的温度随时间而变。

##### 属性的类型
- 定性的（分类的）
    - 标称属性：代表某种类别、编码或者状态，标称属性值不具有有意义的序且不是定量的。例如，邮政编码、性别等。可做=、≠操作。度量操作有众数、熵、卡方检验$\chi ^2$。均值和中位数无意义。二元属性是标称属性的一种。
    - 序数属性：值之间具有有意义的序。例如矿石硬度等。可做<、>操作。度量操作有众数、中位数、中值、百分位，均值意义不大。
- 定量的（数值的）
    - 区间属性：可以计算出不同值之间的差值，但是不能简单描述一个值和另一个值的倍数问题，也就是说不能用比率来谈论这些值。例如温度、日期等。可做+、-操作，度量操作有均值、标准差、皮尔逊相关、t 和 F 检验。
    - 比率属性：可以描述一个值和另一个值的倍数关系。例如：年龄、质量、长度等。可做*、\操作。度量操作有几何平均、调和平均等。
- 注意操作符是累积的，比率属性可做=、≠、>、<、+、-、*、\等。
- 零散属性具有有限个值或无限可数个值。连续属性是取实数值（浮点数）的属性。通常，标称和序数属性是离散的，而区间和比率属性是连续的，但不是绝对的。


### 2.数据质量
数据挖掘使用的数据常常在收集时未明确其目的，不能在源头控制其质量。相比之下，统计学的实验设计或调查往往其数据质量都达到了一定要求。由于无法避免数据质量问题，因此第一步往往需要进行数据清洗。
导致数据质量的原因：
- 测量误差：测量误差是指测量过程中导致的问题，如记录的值与实际值不同。
- 数据收集误差：指诸如遗漏数据对象或属性值，或不当地包含了其他数据对象等错误。
- 测量误差或数据收集误差可能是系统的也可能是随机的。

常见的数据质量问题：
#### （1）噪声<非法无效>
噪声是测量误差，数值可能被扭曲。噪声通常用于包含时间或空间分量的数据。完全消除噪声通常是困难的，许多数据挖掘工作都关注鲁棒算法，即在噪声干扰下也能产生可接受的结果。
#### （2）伪像
数据错误可能是更确定性现象的结果，如一组照片在同一地方出现条纹，数据的这种确定性失真称作伪像。
#### （3）离群点（异常值）<合法有效>
离群点，也称为异常对象、异常值，是在某种意义上具有不同于数据集中其他大部分数据对象的特征的数据对象，或是相对于该属性的典型值来说不寻常的属性值。
- 与噪声不同的是，离群点可以是合法的数据对象或值。因此，不像噪声，离群点本身有时是人们感兴趣的对象。
- 例如，欺诈和网络攻击检测中，目标就是从大量正常对象或事件中发现不正常的对象和事件。

#### （4）遗漏值
一个对象遗漏一个或多个属性值的情况并不少见，有时可能会出现信息收集不全的情况，例如有的人拒绝透露年龄或体重。或者有些情况下某些属性并不能用于所有对象。

处理遗漏值的策略，每种策略可能适用于特定的情况：
- 删除数据对象或属性<br>
如果某个数据值只有少量的对象具有遗漏值，则忽略他们是划算的。但是，可能被删除的属性对分析是至关重要的，此时删除要非常小心。
- 估计遗漏值（平滑、插值）<br>
有时，遗漏值可以可靠的估计。
    - 插值，如果属性是连续的，则可以使用最近邻的平均属性值。如果属性是分类的，则可以取最近邻中最常出现的属性值。
-在分析时忽略遗漏值<br>
许多算法可以修改、忽略遗漏值。但是，如果整个属性数据很少，或者遗漏值的数量很大，则不能忽略遗漏值。

#### （5）数据不一致
例如，身高是负数，地址填的是邮编。需要检测这种不一致的数据，如果可能的话，纠正错误。

#### （6）数据重复
数据集可能包括重复或几乎重复的数据对象。
- 如果重复数据代表相同的对象，需要删除。
- 如果重复数据代表不同的对象，需要添加额外属性避免重复。

#### （7）时效性
有些数据收集后就开始老化，如果数据已过时，则基于它的模型和模式也已经过时。

#### （8）抽样偏倚
抽样偏倚指样本包含的不同类型的对象与它们在总体中的出现情况不成比例。抽样偏倚通常导致不正确的分析。

#### （9）相关性
可用的数据必须包含应用所需要的信息。考虑构造一个模型，预测交通事故发生率，如果忽略了驾驶员的年龄和性别信息，那么除非这些信息可以间接地通过其他属性得到，否则模型的精度可能是有限的。
- 如果若干属性是强相关的，则说明这些属性可能提供了冗余的信息，可以决定只保留一个（如销售税和销售价格）。


### 3.数据的基本统计描述
把握数据的全貌可以更全面的认识数据，基本统计描述可以用来识别数据的性质，凸显哪些数据值应该视为噪声或离群点。
#### （1）中心趋势度量：均值、中位数、众数
中心趋势度量数据分布的中心位置。直观的说，给定一个属性，它的值大部分落在何处？
中心趋势度量包括均值、中位数、众数和中列数。
- 在具有完全对称的数据分布的单峰频率曲线中，均值、中位数、众数都是相同的中心值。
- 在大部分实际应用中，数据都是不对称的。它们可能是正倾斜的，众数出现在小于中位数的值上。负倾斜的话，众数出现在大于中位数的值上。
##### 均值
定义：令$x_1,x_2,...,x_n$为某属性 $X$ 的 $N$ 个观测值，该值集合的均值为$\bar x=\frac{\sum_{i=1}^Nx_i}{N}=\frac{x_1+x_2+...+x_N}{N}$。

特点：
- 数据集“中心”最常用的度量是（算术）均值。

##### 加权算术均值或加权平均
有时，对于 $i=1,...,N$ 的每个值 $x_i$ 可以与一个权重 $w_i$ 相关联。权重反映它们所依附的对应值的意义、重要性或出现的频率。$\bar x=\frac{\sum_{i=1}^Nw_ix_i}{\sum_{i=1}^Nw_i}=\frac{w_1x_1+...+w_Nx_N}{w_1+...+w_N}$。
特点：
- 尽管均值是描述数据集的最有用的单个量，但是它并非总是度量数据的最佳方案。主要问题是均值对极端值（如离群值）很敏感，容易“被平均”。

##### 截尾均值
特点：
- 为了抵消少数极端值的影响，我们可以使用截尾均值。截尾均值是丢弃高低极端值后的均值。

##### 中位数
特点：
- 对于倾斜（非对称）数据，数据中心的更好度量是中位数。中位数是有序数据值的中间值。如果 N 是奇数，中位数是有序集的中间值。如果 N 是偶数，如果 $X$ 是数值，中位数取中间两个值的平均值。如果 $X$ 非数值，中位数取中间两个值之间的任意值。
- 当观测的数量很大时，中位数的计算开销很大。

##### 众数
特点：
- 数据集的众数是集合中出现最频繁的值。
- 可能最高频率对应多个不同值，导致多个众数。具有一个、两个、三个众数的数据集合分别称为单峰、双峰、三峰。
- 极端情况下，如果每个数据值仅出现一次，则它没有众数。

##### 中列数
- 中列数是数据集的最大值和最小值的平均值。

#### （2）数据散布度量：极差、四分位数、方差、标准差、四分位数极差
#### （3）图形显示

### 4.数据的统计指标
#### （1）相关性
- 相关性是一个统计指标，表示两个变量线性相关（即它们以固定的比率一起变化）的程度。它是一个用于描述简单关系而没有陈述因果关系的常用工具。
- 局限：相关性无法告诉我们在所探索的两个变量之外是否存在其他变量，或这些变量有何影响。更重要的是，相关性不能告诉我们因果关系。此外，相关性也无法准确地描述曲线关系。

###### 衡量相关性
相关性通常以两个关键数值来表示：r和p。
- 相关系数r：使用相关系数来描述相关性的强弱，范围是-1~+1。r越接近0，线性关系越弱。正的r值表示正相关，在这种情况下，两个变量的值往往一起增加；负的r值表示负相关，在这种情况下，当一个变量的值增加时，另一个变量的值往往减少。<br>
相关系数有多种定义方式，较为常用的是皮尔逊相关系数。两个变量之间的皮尔逊相关系数定义为两个变量的协方差除以它们标准差的乘积。
    - 总体相关系数（总体皮尔逊系数）
    $$\rho_{X,Y}=\frac{cov(X,Y)}{\sigma_X\sigma_Y}=\frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X\sigma_Y}$$
    - 样本相关系数（样本皮尔逊系数）
    $$r=\frac{\sum_{i=1}^n(X_i-\bar X)(Y_i-\bar Y)}{\sqrt{\sum_{i=1}^n(X_i-\bar X)^2}\sqrt{\sum_{i=1}^n(Y_i-\bar Y)^2}}=\frac{1}{n-1}\sum_{i=1}^n\left (\frac{X_i-\bar X}{\sigma X}\right )\left (\frac{Y_i-\bar Y}{\sigma Y}\right )$$
- 统计显著性p：p值可衡量假设检验所用的概率。p值为我们提供了证据，帮助我们确定能否可以根据从样本中观测到的情况得出有意义的结论，即总体相关系数可能不等于零。

###### 相关性可视化
- 相关表
- 相关图

#### （2）协方差 Covariance


### 3.数据预处理
### 4.数据度量

## （三）数据探查
- 数据探查的出发点是为建模服务，因为我们在建模的时候对数据有要求，所以主要是探查单变量的问题，单变量的分布以及两变量间的关系。

### 1.数据可视化
#### （1）密度图 Density Plot
- 当我们需要观察比较2个变量间的关系时，散点图是我们的首选图表。可当数据量非常大，数据点又比较集中在某个区间中，图表密密麻麻的没法看。这时候就得看密度图了。所谓的密度图就是数据的分布稠密情况，它通常用于显示数据在连续时间段内的分布状况。
- 严格来说，密度图是由直方图演变而来，类似于把直方图进行了填充。一般是使用平滑曲线来绘制数据水平来观察分布，峰值数值是该时间段内最高集中的地方。它比直方图适用性更强，不受分组数量（直方图的条形数量不宜过多）的影响，能更好地界定分布形状。

## （四）分类
## （五）关联分析
## （六）聚类
## （七）异常检测

# 二、数据挖掘方法
## （一）数据挖掘方法总览
- 通常情况下，我们把数据挖掘方法分为两大方面，一是统计类型，有概率分析、相关性、聚类分析和判别分析等常用技术。二是人工智能领域中的机器学习型，通过训练和学习大量的样品集获得需要的模式或参数。

### 1.数理统计分析
- 数理统计是以概率论为基础，研究社会和自然界中大量随机现象数量变化基本规律的一种方法。其重要内容有参数估计、假设检验、相关分析、试验设计、非参数统计。数理统计以随机现象的观察试验取得资料作为出发点，以概率论为理论基础来研究随机现象。根据资料为随机现象选择数学模型，且利用数据资料来验证数学模型是否合适，在合适的基础上再研究它的特点、性质和规律性。数理统计是伴随着概率论的发展而发展起来的一个数学分支。
- 此类技术建立在传统的数理统计基础上。在数据库字段项之间存在两种关系：函数关系（能用函数公式表示的确定性关系）和相关关系（不能用函数公式表示，但仍是相关确定性关系），对它们的分析可采用统计学方法，即利用统计学原理对数据库中的信息进行分析。
- 概率论、数据统计、数据挖掘的关系：概率论与数理统计是数据统计中采用的技术，但其在数据挖掘中也具有十分重要的作用。

#### （1）回归分析
- 回归分析是通过使用变量之间相互依存的定量关系来分析和预测的统计分析方法。

#### （2）相关分析
#### （3）差异分析
#### （4）多元回归分析
#### （5）最小二乘回归分析

### 2.决策树
- 决策树是在情况发生概率已知的前提下，构建决策树来分析项目的概率，用树形结构图解评价是否可行的概率分析方法。

### 3.神经网络

### 4.遗传算法

### 5.关联规则
- 关联规则是简单、使用、易于理解的数据挖掘方法，能在交易数据、关系数据或其他信息载体中，查找存在于项目集合或对象集合之间的频繁模式、关联、相关性或因果结构。

### 6.聚类分析

