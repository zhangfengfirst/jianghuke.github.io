# 一、Pandas
## 1.Pandas对象
如果从底层视角观察Pandas对象，可以把它们看成增强版的NumPy结构化数组，行列都不再只是简单的整数索引，还可以带上标签。

Pandas的每一个工具、方法和功能几乎都需要我们理解基本数据结构的内部细节。因此，需掌握Pandas的三个基本数据结构：Serises、DataFrame、Index。

### 1.1.Series对象

#### （1）Series是什么
Pandas的Series对象是一个带「索引」数据结构的「一维」数组。

可以用一个数组创建Series对象，如下所示：
```
import pandas as pd
data = pd.Series([0.1, 0.3, 0.5])
data
0    0.1
1    0.3
2    0.5
dtype: float64
```
以上，Series对象将一组数据和一组索引绑定在一起。可以通过values属性和index属性获取一维数组和索引标签。

```
data.values
out:array([0.1, 0.3, 0.5])
data.index
out:RangeIndex(start=0, stop=3, step=1)
```

#### （2）Series与一维NumPy数组比较
Series对象比一维NumPy数组更加通用，灵活。

##### a.Series是通用的NumPy数组
Series对象和一维NumPy数组基本可以等价交换，但两者间的本质差异其实是索引：NumPy数组通过「隐式定义」的「整数索引」获取数值，Series对象用一种「显式定义」的「任意类型索引」与数值关联。

- Series显式定义索引
- Series定义的索引可以是任意类型，如字符串。

**使用字符串定义索引并索引数据**
```
data = pd.Series([0.1, 0.3, 0.5],index=['a','b','c'])
data
out:
a    0.1
b    0.3
c    0.5
dtype: float64
data['b']
out:0.3
```

**使用不连续的整数定义索引并索引数据**
```
data = pd.Series([0.1, 0.3, 0.5],index=[5,20,2])
data
out:
5     0.1
20    0.3
2     0.5
dtype: float64
data[20]
out:0.3
```

##### b.Series是特殊的字典
可以把Pandas的Series对象看成是一种特殊的python字典。字典是一种将任意键映射到一组任意值得数据结构，Series对象其实是一种将类型键映射到一组类型值得数据结构。类型至关重要：就像NumPy数组背后特定类型的经过编译的代码使得它在某些操作上比普通的Python列表更加高效一样，Pandas Series的类型信息使得它在某些操作上比Python的字典更高效。

可以直接用Python的字典创建一个Series对象，让Series对象与字典的额类比更加清晰：
```
population_dict={'北京':2154,'上海':2632,'广州':1531,'深圳':1259}
population = pd.Series(population_dict)
population
out:
北京    2154
上海    2632
广州    1531
深圳    1259
dtype: int64
```

索引获取数据
```
population['北京']
out:
2154
```
切片获取数据
```
population['上海':'深圳']
out:
上海    2632
广州    1531
深圳    1259
dtype: int64
```
#### （3）创建对象
创建Series对象的语法是 `pd.Series(data, index=index)`
- data参数支持多种数据类型，index是一个可选参数。可以通过显式指定索引获取数据
- data可以是列表或NumPy数组，这时index默认值维整数序列
```
pd.Series([1,3,5])
out:
0    1
1    3
2    5
dtype: int64
```
- data可以是一个标量，创建Series对象时会重复填充到每个索引上
```
pd.Series(5, index=[100,200,300])
out:
100    5
200    5
300    5
dtype: int64
```
- data可以是一个字典，index默认是排序的字典键
```
pd.Series({2:'a',1:'b',3:'c'})
out:
2    a
1    b
3    c
dtype: object
```

#### ➤➤➤ Series属性 ➤➤➤
#### （3）Series.values属性

#### （4）Series.index属性

#### （5）获取数据
可以通过显式指定索引获取数据。


### 1.2.DataFrame对象
#### （1）DataFrame是什么
- 如果将Series类比为带灵活索引的一维数组，那么DataFrame就可以看做是一种既有「灵活的行索引」，又有「灵活列名」的二维数组。就像可以把二维数组看成是有序排序的一维数组一样，可以把DataFrame看成是有序排列的若干Series对象。

#### （2）DataFrame与二维NumPy数组比较
##### a.DataFrame是通用的NumPy数组

##### b.DataFrame是特殊的字典

#### ➤➤➤ 创建对象 ➤➤➤
DataFrame对象可以通过许多方式创建。
#### （1）构造函数
`DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)`
- data:ndarray (structured or homogeneous), Iterable, dict, or DataFrame. Dict can contain Series, arrays, constants, dataclass or list-like objects.如果data是一个字典，列顺序遵循插入顺序。
- index
- columns:Index or array-like
- dtype
- copy

#### （2）通过单个Series对象创建
DataFrame是一组Series对象的集合，可以用单个Series创建一个单列的DataFrame。
```
population_dict={'北京':2154,'上海':2632,'广州':1531,'深圳':1259}
population = pd.Series(population_dict)
population
out:
北京    2154
上海    2632
广州    1531
深圳    1259
dtype: int64
pd.DataFrame(population, columns=['population'])
out:
population
北京	2154
上海	2632
广州	1531
深圳	1259
```

#### （3）通过字典列表（list of dicts）创建
任何元素是字典的列表都可以变成DataFrame
```
data = [{'a':i, 'b':2*i} for i in range(3)]
pd.DataFrame(data)
out:
a	b
0	0	0
1	1	2
2	2	4
```
#### （4）通过Series对象字典创建
可以用一个由Series对象构成的字典创建DataFrame
```
population_dict={'北京':2154,'上海':2632,'广州':1531,'深圳':1259}
population = pd.Series(population_dict)
area_dict={'北京':16410,'上海':6340,'广州':7434,'深圳':1997}
area = pd.Series(area_dict)
pd.DataFrame({'population':population,'area':area})
out:
population	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
深圳	1259	1997
```

#### （5）通过NumPy二维数组创建
假如有一个二维数组，就可以创建一个可以指定行列索引值的DataFrame。如果不指定行列索引值，那么行列默认都是整数索引值。
```
pd.DataFrame(np.random.rand(3,2))
out:
    0	1
0	0.783028	0.184407
1	0.726870	0.685593
2	0.757775	0.806291
pd.DataFrame(np.random.rand(3,2),columns=['foo','bar'],index=['a','b','c'])
out:
    foo	bar
a	0.757035	0.684511
b	0.790210	0.807101
c	0.032117	0.170443

```
#### （6）通过NumPy结构化数组创建。

#### ➤➤➤ 数据选择 ➤➤➤
#### （1）将DataFrame当做字典

##### a.字典形式（dictionary-style）

把DataFrame当做一个由若干个Series对象构成的字典。
```
pop = pd.Series({'北京':2154,'上海':2632,'广州':1531,'深圳':1259})
area = pd.Series({'北京':16410,'上海':6340,'广州':7434,'深圳':1997})
data = pd.DataFrame({'pop':pop,'area':area})
data
out:
        pop	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
深圳	1259	1997
```
两个Series分别构成DataFrame的一列，可以通过对列名进行字典形式（dictionary-style）的取值获取数据。
```
data['area']
out:
北京    16410
上海     6340
广州     7434
深圳     1997
Name: area, dtype: int64
```
##### b.属性形式（attribute-style）
可以用属性形式（attribute-style）选择纯字符串列名的数据。
```
data.area
out:
北京    16410
上海     6340
广州     7434
深圳     1997
Name: area, dtype: int64
```
虽然属性形式的数据选择方法很方便，但是它并不是通用的。
- 如果列名不是纯字符串
- 或者列名与DataFrame的方法同名

就不能用属性索引。
```
data.pop
out:
<bound method DataFrame.pop of      pop   area
北京  2154  16410
上海  2632   6340
广州  1531   7434
深圳  1259   1997>
```
为避免歧义，尽量不使用属性形式选择数据。

#### （3）将DataFrame看做二维数组
可以把DataFrame看做是一个增强版的二维数组

##### a.values属性按行查看数组数据
用values属性按行查看数组数据。
```
data.values
out:
array([[ 2154, 16410],
       [ 2632,  6340],
       [ 1531,  7434],
       [ 1259,  1997]], dtype=int64)
```

##### b.对DataFrame进行行列转置
```
data
out:
	    pop	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
深圳	1259	1997
data.T
out:
    北京	上海	广州	深圳
pop	2154	2632	1531	1259
area	16410	6340	7434	1997
```

##### c.用单个行索引获取一行数据
```
data
out:
pop	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
深圳	1259	1997
data.values[0]
out:
array([ 2154, 16410], dtype=int64)
```

##### d.用单个列索引获取一列数据
```
data['area']
out:
北京    16410
上海     6340
广州     7434
深圳     1997
Name: area, dtype: int64
```

##### e.索引器获取数据
接下来，将DataFrame当做数组时，通过loc、iloc、ix索引器，我们就可以像对待NumPy数组一样索引Pandas的底层数组（Python的隐式索引），DataFrame的行列标签会自动保留在结果中。
```
data
out:
  pop	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
深圳	1259	1997
data.iloc[:3,:2]
out:
  pop	area
北京	2154	16410
上海	2632	6340
广州	1531	7434
```
 
### 1.3.Index对象
## 2.类sql操作
### 2.1.GroupBy
可以使用分割（split）、应用（apply）、组合（combine）来理解GroupBy操作。
- 分割步骤将DataFrame按照指定键分割成若干组。
- 应用步骤对每个组应用函数、通常是累计、转换或过滤函数。
- 组合步骤将每一组的结果合并成一个输出数组。

![groupby](img/groupby.png)

GroupBy操作经常只需一行代码，就可以计算每组的和、均值、计数、最小值以及其他累计值。GroupBy的用处就是将这些步骤进行抽象，用户不需要知道在底层如何计算，只要把操作看成一个整体就够了。

#### （1）groupby对象
```
df = pd.DataFrame({'key':['A','B','C','A','B','C'],'data':range(6)},columns=['key','data'])
df
out:
	key	data
0	A	0
1	B	1
2	C	2
3	A	3
4	B	4
5	C	5
df.groupby('key')
out:
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000190053734F0>
```
`df.groupby()`的返回值不是一个DataFrame对象，而是一个DataFrameGroupBy对象。这个对象的魔力在于，可以将它看成是一种特殊形式的DataFrame，里面隐藏着若干组数据，但是在乜有应用累计函数之前不会计算（已经执行了分组操作，应用累计函数就会完成相应的应用/组合步骤并生成结果）。这种延迟计算（lazy evaluation）的方法使得大多数常见的累计操作可以通过一种对用户而言几乎是透明的方式非常高效的实现。

#### ➤➤➤ groupby按列取值 ➤➤➤
数据集：
```
df = pd.DataFrame({'班级':['331','331','331','331','331','331','331','332','332','332','332','332','332','333','333','333','333','333'],
                   '姓名':['张1','张2','张3','李1','李2','李3','王1','王2','王3','赵1','赵2','孙1','孙2','孙3','钱1','钱2','宋1','宋2'],
                   '性别':['男','男','男','女','女','女','女','男','男','男','女','女','女','男','男','女','女','女'],
                   '身高':[175,182,179,159,163,165,170,189,178,177,159,160,170,180,179,163,158,169],
                   '成绩':[98,90,96,99,96,95,92,81,83,85,87,82,85,71,73,78,77,76]},
                 columns=['班级','姓名','性别','身高','成绩'])
out:
	班级	姓名	性别	身高	成绩
0	331	张1	男	175	98
1	331	张2	男	182	90
2	331	张3	男	179	96
3	331	李1	女	159	99
4	331	李2	女	163	96
5	331	李3	女	165	95
6	331	王1	女	170	92
7	332	王2	男	189	81
8	332	王3	男	178	83
9	332	赵1	男	177	85
10	332	赵2	女	159	87
11	332	孙1	女	160	82
12	332	孙2	女	170	85
13	333	孙3	男	180	71
14	333	钱1	男	179	73
15	333	钱2	女	163	78
16	333	宋1	女	158	77
17	333	宋2	女	169	76
```
#### （1）按列取值
GroupBy 对象与DataFrame一样，也支持按列取值，并返回一个修改过的GroupBy对象。`df.groupby('XX1')['XX2']`

```
df.groupby('班级')
out:
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000190071E39D0>
df.groupby('班级')['成绩']
out:
<pandas.core.groupby.generic.SeriesGroupBy object at 0x00000190071E3820>
```
这里从原来的DataFrame中取某个列名作为一个Series组。

#### （2）按列取值并对该列进行操作
按列取值返回一个修改过的groupby对象，同样，直到我们运行累计函数，才会开始计算。

```
df.groupby('班级')['成绩'].count()
out:
班级
331    7
332    6
333    5
Name: 成绩, dtype: int64

df.groupby('班级')['成绩'].mean()
out:
班级
331    95.142857
332    83.833333
333    75.000000
Name: 成绩, dtype: float64
```

#### ➤➤➤ groupby对象的操作方法 ➤➤➤
#### （1）describe()
对数据表中的「数值列」进行统计，不会对非数值列统计。

统计信息包括：count、mean、std、min、25%、50%、75%、max。

```
df.groupby('班级').describe()
out:
身高	成绩
count	mean	std	min	25%	50%	75%	max	count	mean	std	min	25%	50%	75%	max
班级																
331	7.0	170.428571	8.599557	159.0	164.0	170.0	177.00	182.0	7.0	95.142857	3.184785	90.0	93.50	96.0	97.0	99.0
332	6.0	172.166667	11.548449	159.0	162.5	173.5	177.75	189.0	6.0	83.833333	2.228602	81.0	82.25	84.0	85.0	87.0
333	5.0	169.800000	9.679876	158.0	163.0	169.0	179.00	180.0	5.0	75.000000	2.915476	71.0	73.00	76.0	77.0	78.0
```
unstack()可以将每列的统计信息垂直排列。

#### （2）mean()
每组内，统计所有数值列的均值，非数值列无均值。
```
df.groupby('班级').mean()
out:
身高	成绩
班级		
331	170.428571	95.142857
332	172.166667	83.833333
333	169.800000	75.000000
```

其他操作还有：sum()、count()、median()、max()、min()、std()、var()、quantile()

#### ➤➤➤ groupby对象的聚合、过滤、转换、应用操作 ➤➤➤
GroupBy对象是一种非常灵活的抽象类型，在大多数场景中，可以将它看成是DataFrame的集合，在底层解决所有难题。

GroupBy中重要的操作可能就是aggregate（聚合）、filter（过滤）、transform（转换）和apply（应用）了。

数据集：使用以下这个DataFrame。
```
rng = np.random.RandomState(0)
df = pd.DataFrame({'key':['A','B','C','A','B','C'],'data1':range(6),'data2':rng.randint(0,10,6)},columns=['key','data1','data2'])
df
out:
key	data1	data2
0	A	0	5
1	B	1	0
2	C	2	3
3	A	3	3
4	B	4	7
5	C	5	9
```
#### （1）聚合aggregate
聚合操作是groupby后非常常见的操作，聚合操作可以用来求和、均值、最大值、最小值。聚合操作有：min、max、sum、mean、median、std、var、count。

##### a、按某列分组，其余所有列指定一个聚合操作
```
df.groupby('key').agg('mean')
out:
data1	data2
key		
A	1.5	4.0
B	2.5	3.5
C	3.5	6.0
```

##### b、按某列分组，其余所有列指定多个聚合操作
```
df.groupby('key').aggregate(['sum','mean','max'])
out:
	data1	data2
sum	mean	max	sum	mean	max
key						
A	3	1.5	3	8	4.0	5
B	5	2.5	4	7	3.5	7
C	7	3.5	5	12	6.0	9
```

##### c、按某列分组，指定列指定一个聚合操作
```
df.groupby('key').agg({'data1':'min','data2':'max'})
out:
data1	data2
key		
A	0	5
B	1	7
C	2	9
```

##### d、按某列分组，指定列指定多个聚合操作
```
df.groupby('key').agg({'data1':['min','max'],'data2':'max'})
out:
data1	data2
min	max	max
key			
A	0	3	5
B	1	4	7
C	2	5	9
```

##### e、按多个列分组
```
rng = np.random.RandomState(0)
df = pd.DataFrame({'key1':['A','B','C','A','B','C'],'key2':['X','X','X','Y','Y','Y'],'data1':range(6),'data2':rng.randint(0,10,6)},columns=['key1','key2','data1','data2'])
df
out:
key1	key2	data1	data2
0	A	X	0	5
1	B	X	1	0
2	C	X	2	3
3	A	Y	3	3
4	B	Y	4	7
5	C	Y	5	9

df.groupby(['key1','key2']).aggregate('mean')
```



#### （1）count计数

#### （2）分组计数
```python
from sklearn.datasets import load_boston
import pandas as pd
boston = load_boston()
df=pd.concat([pd.DataFrame(boston.data),pd.DataFrame(boston.target)],axis=1)
df.columns=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']

df['RAD'].groupby(df.RAD).count()
```

## 9.最佳实践
### 9.1.DataFrame属性
#### （1）示例数据集
数据集：
```
df = pd.DataFrame({'班级':['331','331','331','331','331','331','331','332','332','332','332','332','332','333','333','333','333','333'],
                   '姓名':['张1','张2','张3','李1','李2','李3','王1','王2','王3','赵1','赵2','孙1','孙2','孙3','钱1','钱2','宋1','宋2'],
                   '性别':['男','男','男','女','女','女','女','男','男','男','女','女','女','男','男','女','女','女'],
                   '身高':[175,182,179,159,163,165,170,189,178,177,159,160,170,180,179,163,158,169],
                   '成绩':[98,90,96,99,96,95,92,81,83,85,87,82,85,71,73,78,77,76]},
                 columns=['班级','姓名','性别','身高','成绩'])
out:
	班级	姓名	性别	身高	成绩
0	331	张1	男	175	98
1	331	张2	男	182	90
2	331	张3	男	179	96
3	331	李1	女	159	99
4	331	李2	女	163	96
5	331	李3	女	165	95
6	331	王1	女	170	92
7	332	王2	男	189	81
8	332	王3	男	178	83
9	332	赵1	男	177	85
10	332	赵2	女	159	87
11	332	孙1	女	160	82
12	332	孙2	女	170	85
13	333	孙3	男	180	71
14	333	钱1	男	179	73
15	333	钱2	女	163	78
16	333	宋1	女	158	77
17	333	宋2	女	169	76
```
#### （2）DataFrame.index
DataFrame的索引，行标签。
```python
df.index
out:
RangeIndex(start=0, stop=18, step=1)
```
#### （3）DataFrame.columns
DataFrame的列标签
```python
df.columns
out:
Index(['班级', '姓名', '性别', '身高', '成绩'], dtype='object')
```

#### （4）DataFrame.dtypes
返回DataFrame的数据类型。返回一个Series，表示原始df每列的数据类型。Series的索引是原始df的列。
```python
df.types
out:
班级    object
姓名    object
性别    object
身高     int64
成绩     int64
dtype: object
```
#### （5）DataFrame.axes
返回一个列表list，表示df的轴，列表的成员是：行轴标签和列轴标签。
```python
df.axes
out:
[RangeIndex(start=0, stop=18, step=1),
 Index(['班级', '姓名', '性别', '身高', '成绩'], dtype='object')]
```
#### （6）DataFrame.ndim
返回一个整数，表示轴数或者数组的维数。

如果是Series，则返回1；如果是DataFrame，则返回2。
```python
df.ndim
out:
2
```
#### （7）DataFrame.size
返回一个整数，表示df对象中元素数量。

如果是Series，则返回行数；如果是DataFrame，则返回行数乘以列数。
```python
df.size
out:
90
```
#### （8）DataFrame.shape
返回一个元组，表示df的维数。
```python
df.shape
out:
(18, 5)
```
### 9.2.DataFrame方法
#### （1）DataFrame.columns
```python

out:

```

### 9.3.数据选择
#### （1）字典形式选择列
```python
df['姓名']
out:
0     张1
1     张2
2     张3
3     李1

type(df['姓名'])
out:
pandas.core.series.Series
```

### 9.4.DF增加列
#### （1）pandas.DataFrame.insert
向df指定位置插入列
`DataFrame.insert(loc, column, value, allow_duplicates=False)`
#### （2）直接赋值法
`df['新列名']=新列的值`

#### （3）



### 9.4.类型转换
#### （1）pd.dataframe 转 np.array
```python
df.to_numpy()
out:
array([['331', '张1', '男', 175, 98],
       ['331', '张2', '男', 182, 90],
       ['331', '张3', '男', 179, 96],
       ['331', '李1', '女', 159, 99],
       ['331', '李2', '女', 163, 96],
       ['331', '李3', '女', 165, 95],
       ['331', '王1', '女', 170, 92],
       ['332', '王2', '男', 189, 81],
       ['332', '王3', '男', 178, 83],
       ['332', '赵1', '男', 177, 85],
       ['332', '赵2', '女', 159, 87],
       ['332', '孙1', '女', 160, 82],
       ['332', '孙2', '女', 170, 85],
       ['333', '孙3', '男', 180, 71],
       ['333', '钱1', '男', 179, 73],
       ['333', '钱2', '女', 163, 78],
       ['333', '宋1', '女', 158, 77],
       ['333', '宋2', '女', 169, 76]], dtype=object)

df.to_numpy().shape
out:
(18, 5)
```

### 9.5.合并数据集
#### ➤➤➤ pandas.concat()
连接pandas对象，沿着一个指定的轴连接pandas对象，沿着另一个轴使用可选的设置逻辑。
#### （1）默认纵向连接
`pd.concat([df1,df2])`默认纵向连接两个df对象，并且合并之后不改变每个df子对象的index值，因此我们可以在合并之后的df中看到index的值0和1重复了两次。

两个df列标签相同，默认纵向连接，合并后列标签不变，行标签保持。
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter','number'])
df2=pd.DataFrame([['c',3],['d',4]],columns=['letter','number'])
df3=pd.concat([df1,df2])
out:
    letter	number
0	a	1
1	b	2

    letter	number
0	c	3
1	d	4

    letter	number
0	a	1
1	b	2
0	c	3
1	d	4
```
#### （2）纵向连接，忽略行标签
两个df列标签相同，默认纵向连接，合并后列标签不变，忽略行标签，重置行标签。
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter','number'])
df2=pd.DataFrame([['c',3],['d',4]],columns=['letter','number'])
df3=pd.concat([df1,df2],ignore_index=True)
out:
    letter	number
0	a	1
1	b	2

    letter	number
0	c	3
1	d	4

    letter	number
0	a	1
1	b	2
2	c	3
3	d	4
```
#### （3）纵向连接，列名不同
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter1','number'])
df2=pd.DataFrame([['c',3],['d',4]],columns=['letter2','number'])
df3=pd.concat([df1,df2],ignore_index=True)
out:
    letter1	number
0	a	1
1	b	2

    letter2	number
0	c	3
1	d	4

    letter1	number	letter2
0	a	1	NaN
1	b	2	NaN
2	NaN	3	c
3	NaN	4	d
```
#### （4）纵向连接，列个数不同
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter','number'])
df2=pd.DataFrame([['c',3,'cat'],['d',4,'dog']],columns=['letter','number','animal'])
df3=pd.concat([df1,df2],ignore_index=True)
out:
    letter	number
0	a	1
1	b	2

    letter	number
0	c	3
1	d	4

    letter	number	animal
0	a	1	NaN
1	b	2	NaN
2	c	3	cat
3	d	4	dog
```
#### （5）纵向连接，合并相同列
join默认是`outer`，设置`join='inner'`后合并相同列
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter1','number'])
df2=pd.DataFrame([['c',3,'cat'],['d',4,'dog']],columns=['letter2','number','animal'])
df3=pd.concat([df1,df2],ignore_index=True,join='inner')
out:
    letter1	number
0	a	1
1	b	2

    letter2	number	animal
0	c	3	cat
1	d	4	dog

    number
0	1
1	2
2	3
3	4
```

#### （1）横向连接
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter','number'])
df2=pd.DataFrame([['c',3,'cat'],['d',4,'dog']],columns=['letter','number','animal'])
df3=pd.concat([df1,df2],axis=1)
out:
    letter	number
0	a	1
1	b	2

    letter	number	animal
0	c	3	cat
1	d	4	dog

    letter	number	letter	number	animal
0	a	1	c	3	cat
1	b	2	d	4	dog
```

#### ➤➤➤ DataFrame.append()
将另一个df的行附到调用者的末尾，范围一个新对象。`1.4.0`版本已经弃用，使用`concat()`代替。

#### ➤➤➤ DataFrame.join()
- join将一个或多个df加入到当前df中，实现合并的功能。
- join方法默认以左连接的方式进行合并，默认的连接列是df的行标签
- join合并两个df时，两个df中不能有相同的列名，如果两个df具有相同名字的列，需要手动指定后缀（merge方法会自动给相同的列名加后缀）
- join默认使用行标签连接，如果有on参数，则用on参数指定的列名来连接
- on指定调用的df中用于连接的列（这里是df1），传入join方法的df2还是用行标签进行连接。
- on参数指定多个列作为连接列时，这些列都要在调用者df1中，此时，传入join方法的df2必须为重行索引，且与on指定的列数相等，否则会报错。

#### （1）具有相同列名的df关联，报错
```python
df1=pd.DataFrame([['a',1],['b',2]],columns=['letter','number'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat']],columns=['letter','number','animal'])
df1.join(df2)
out:
    letter	number
0	a	1
1	b	2

    letter	number	animal
0	b	2	bear
1	c	3	cat

ValueError: columns overlap but no suffix specified: Index(['letter', 'number'], dtype='object')
列名重叠没有指定后缀

```
#### （2）默认行索引关联
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter1','number1'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat']],columns=['letter2','number2','animal2'])
df3=df1.join(df2)
out:
    letter1	number1
0	a	1
1	b	2
2	d	4

    letter2	number2	animal2
0	b	2	bear
1	c	3	cat

	letter1	number1	letter2	number2	animal2
0	a	1	b	2.0	bear
1	b	2	c	3.0	cat
2	d	4	NaN	NaN	NaN

```

#### （3）默认行索引关联，指定inner连接方式
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter1','number1'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat']],columns=['letter2','number2','animal2'])
df3=df1.join(df2,how='inner')
out:
    letter1	number1
0	a	1
1	b	2
2	d	4

    letter2	number2	animal2
0	b	2	bear
1	c	3	cat

	letter1	number1	letter2	number2	animal2
0	a	1	b	2	bear
1	b	2	c	3	cat
```

#### ➤➤➤ DataFrame.merge()/pd.merge()
- pd.merge()和DataFrame.merge()，这两个方法的用法一样
- merge方法默认，自动把2个df中有相同列名的列作为主键列关联。
- 最好是明确指定on参数，此时列名必须同时在2个df中出现
- 如果两个df中没有相同列名，则使用left_on和right_on参数作为关联列，明确指定2个df要关联的列。
- 关联条件on：如果2个df有相同的列且要作为主键列，则参数用on；如果2个df没有相同的列名，则用left_on和right_on
- merge方法默认的关联方式是inner
- merge方法紫菜的参数suffixes，可以自动处理重复的列名。也可以自定义后缀 suffixes=('_left','_right')

#### （1）不同列名，1个列做关联
2个df具有不同的列名，关联条件是1个列
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter1','number1'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat'],['d',5,'dog']],columns=['letter2','number2','animal2'])
df3=pd.merge(df1,df2,left_on="letter1",right_on="letter2")
out:
    letter1	number1
0	a	1
1	b	2
2	d	4

   letter2	number2	animal2
0	b	2	bear
1	c	3	cat
2	d	5	dog

    letter1	number1	letter2	number2	animal2
0	b	2	b	2	bear
1	d	4	d	5	dog
```
#### （2）不同列名，2个列做关联
2个df具有不同的列名，关联条件是2个列
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter1','number1'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat'],['d',5,'dog']],columns=['letter2','number2','animal2'])
df3=pd.merge(df1,df2,left_on=["letter1","number1"],right_on=["letter2","number2"])
out:
    letter1	number1
0	a	1
1	b	2
2	d	4

   letter2	number2	animal2
0	b	2	bear
1	c	3	cat
2	d	5	dog

    letter1	number1	letter2	number2	animal2
0	b	2	b	2	bear
```

#### （3）相同列名，1个列做关联
2个df具有相同的列名，关联条件是1个列
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter','number'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat'],['d',5,'dog']],columns=['letter','number','animal'])
df3=pd.merge(df1,df2,on='letter')
out:
    letter	number
0	a	1
1	b	2
2	d	4

   letter	number	animal
0	b	2	bear
1	c	3	cat
2	d	5	dog

    letter	number_x	number_y	animal
0	b	2	2	bear
1	d	4	5	dog
```
#### （4）相同列名，2个列做关联
2个df具有相同的列名，关联条件是2个列
```python
df1=pd.DataFrame([['a',1],['b',2],['d',4]],columns=['letter','number'])
df2=pd.DataFrame([['b',2,'bear'],['c',3,'cat'],['d',5,'dog']],columns=['letter','number','animal'])
df3=pd.merge(df1,df2,on=['letter','number'])
out:
    letter	number
0	a	1
1	b	2
2	d	4

   letter	number	animal
0	b	2	bear
1	c	3	cat
2	d	5	dog

    letter	number	animal
0	b	2	bear
```

#### ➤➤➤concat、join、merge三者比较


# 二、NumPy

# 三、数据可视化
## 1.前言
### （1）数据可视化
数据可视化是以图示或图形格式表示的数据。让决策者可以看到以直观方式呈现的分析，以便他们可以掌握困难的概念或识别新的模式。

### （2）交互式可视化

## 2.matplotlib
### 2.1.概念
#### （1）matplotlib

## 3.seaborn
### 3.1.前言
#### （1）seaborn
- matplotlib应该是基于python语言最优秀的绘图库了，但是它有一个十分头疼的问题，就是太过于复杂。3000多页的官方文档，上千个方法以及数万个参数，属实是可以用它做任何事，但是又无从下手。seaborn是基于matplotlib核心库进行了更高阶的API封装，可以更轻松的画出漂亮的图形。seaborn的漂亮主要体现在配色更加舒服、以及图形元素的样式更加细腻。

### （2）seaborn特点
- 内置数个经过优化的样式效果
- 单变量和双变量分布绘图更为简单，可用于对数据子集相互比较
- 与NumPy和Pandas数据结构配合良好
- Pandas是一个用于管理关系（表格式）数据集的优秀库，DataFrame时用于数据分析的最广泛使用的数据结构，seaborn在处理DataFrame时非常方便。



